\documentclass{segabs}
%\documentclass[manuscript,ulem,graphix,revised]{geophysics}

\usepackage{amsmath}
\usepackage{graphicx}
%\usepackage{epstopdf}
%\usepackage{slashbox}
\usepackage{hanging}
\usepackage{mathrsfs}
\usepackage{marginnote}
\usepackage{amssymb} 
\usepackage{url}
\usepackage{makecell}


%\usepackage{tikz}
%\usepackage{geometry}
%\usepackage{setspace}
%\usepackage[margin=0.8in]{geometry}
%\usepackage{float}
%\usepackage{subfig}
%\usepackage{subcaption}

\usepackage{indentfirst}
\makeatletter
\newcommand*{\rom}[1]{\expandafter\@slowromancap\romannumeral #1@}
\makeatother
\begin{document}

\title{Velocity model building with a modified fully convolutional network}

\renewcommand{\thefootnote}{\fnsymbol{footnote}} 

\address{
\footnotemark[1]Department of Mathematics, Harbin Institute of Technology,
92 Xidazhi St., Nangang Dist., Harbin, Heilongjiang, China 150001

%\footnotemark[2]Center for Lithospheric Studies, 
%The University of Texas at Dallas, \\
%800 W Campbell Road (ROC21), Richardson, TX, USA 75080
}

\author{Wenlong Wang, Fangshu Yang and Jianwei Ma, Harbin Institute of Technology}

%\footer{Wang \& McMechan}
%\lefthead{Wang \& McMechan}
%\righthead{Salt delineation with FCN}

\maketitle

%\clearpage
%\newpage
\renewcommand{\figdir}{../Fig} % figure directory

\begin{abstract}
We introduce a novel method to estimate the P-wave velocity models directly from the prestack seismic traces using a modified fully convolutional network. The network is tuned to map multi-shot seismic traces to velocity models.
We train the network with pairs of synthetic velocity model and corresponding seismic traces which are simulated from the velocity model with acoustic wave equations. 
Multiple shots are used as channels in the network to increase data redundancy.
The training process is expensive, but it only occurs once up front. 
The trained network is then used to predict velocity models from testing seismic traces, and it shows satisfactory prediction results. The cost for predicting velocity models is negligible once the training is complete.
%The cost for predicting velocity models using the trained network is negligible. 
%Tests with synthetic data show satisfactory results.

\end{abstract}

\section{Introduction}

Velocity model building is an essential step in seismic exploration. Good velocity models are prerequisites for reverse time migration \citep{mcmec83} and other seismic imaging techniques. The estimated velocity models can also be used as initial models to recursively generate high resolution velocity models with optimization algorithms \citep{tarantola84}.
Common practices for generating velocity models include tomography and full-waveform inversion (FWI). However, both tomography and FWI are time-consuming, computationally expensive, and rely heavily on human interactions and quality control. 

Recent developments of machine learning (ML) technologies provide the possibility to reduce or completely remove human intervention from many formerly human-curated activities, for example, image recognition, voice recognition and etc. Geophysicists may also be empowered with those new technologies, and seek possible applications in seismic data processing routines to minimize human intervenes.

Many ML algorithms are built with artificial neural networks (NNs), which have a long history being used in geophysics. However, most of the applications of NNs focus on pattern recognition in seismic attributes  \citep{zeng04,zhao15} and faces classification in well logs \citep{lim05,hall16}. A more challenging and interesting application is to input the network with prestack seismic traces and train the network to directly give geological interpretations of the subsurface. Early pioneers who implement NNs for velocity estimation include \citet{roth94} and \citet{nath99}.
In 2014, \citet{zhang14} propose to use neural networks for automatic fault prediction from seismic traces. Araya-Polo \citet{araya18} build velocity models from seismic traces with a deep neural network (DNN) and a feature extraction step to reduce computational cost. 

In this paper, we work on the same problem of velocity model building from prestack seismic traces, but we use a modified fully convolutional network (FCN) \citep{long15}, which has fewer parameters and thus is more efficient than DNNs. Multiple shots can be easily cooperated as channels. 
The paper is organized as follows, we first introduce the architecture of the network for velocity model building using seismic data. Tests with synthetic data are then performed to show the results. To limit the scope of this paper, we focus on 2D isotropic acoustic models with a uniform and constant density.


\section{Methodology}

Velocity model building from seismic traces is challenging because it involves data transformation from seismic traces ($x$ - $t$) to the space/model domain ($x$ - $z$), which poses as an inverse problem. Neural networks are capable of approximating any continuous function up to a specified accuracy \citep{hornik89}, which provides the theoretical basis for this research.

FCN is a state-of-the-art network that performs pixel-wise semantic segmentation for images. The prototype of FCN consists of a series of convolutional units (convolution, pooling, and activation functions) and deconvolution layers for upsampling. A UNet architecture \citep{ronneberger15} is built on FCN by constructing a U-shaped network which has a symmetric shape of an encoder and a decoder with interconnections across the network [see Figure 1 in \citet{ronneberger15}], and demonstrates improved prediction accuracy with limited training samples. 

To achieve velocity model building from seismic traces, we made two major modifications to the UNet architecture (Figure~\ref{fig:sketch_vnet.eps}).
First, the original UNet is designed for image segmentation and reads input images in RGB color channels, while for processing seismic data, we assign different shot gathers, which are recorded from sources at different locations in the same model, as channels for the input. So the number of channels for the input is the same as the number of sources for each model. The multi-shot seismic data are fed into the network together to improve data redundancy. Second, different from an original UNet architecture, whose output and input are in the same (image) domain and share the same size. We train the network to perform domain transformation from seismic data domain ($x$ - $t$) to the model domain ($x$ - $z$). To handle the size discrepancy between inputs and outputs, we truncate the final output layer to the size of the model before applying the loss function. The proposed network in Figure~\ref{fig:sketch_vnet.eps} is capable of training itself during the encoding and decoding processes to map the seismic data to the model domain.
A similar network is built for automatic salt detection \citep{wenlong18_salt} with a different loss function for classification. 

\fullplot{sketch_vnet.eps}{width=1.0\textwidth}
{A modified UNet architecture for velocity model building using multi-shot seismic traces. Courtesy of \citet{ronneberger15} Figure 1.}

A loss function measures the distance between the prediction and the ground truth (true velocity model). The loss function that we use in the network is defined as the squared difference (L2) between the ground truth velocity model $V$ and the predicted velocity model $\tilde{V}$
\begin{equation}
E = \frac{1}{N}\sum_{\boldsymbol{x}} [V(x)-\tilde{V}(x)]^2,
\label{loss}
\end{equation}
where $N$ is the number of grid points in the model, and $\boldsymbol{x}$ indicates the pixel positions. The ground truth velocity models $V$ is given during the training process, but are hidden for testing after the training. Note that the loss function is different from that in a full wave inversion, in which the loss function measures the squared difference between observed and simulated seismograms.


\section{Synthetic Tests}
In this section, we test the proposed algorithm with synthetic data. 
We generate 1020 velocity models, and assign 1000 of them as training samples, and the other 20 for testing. Each of the models have 2, 3 or 4 layers as background velocity, and the velocity of each layer ranges arbitrarily from 2500 to 3500 m/s with smooth interface curvatures and increases with depth. 
A salt body with an arbitrary shape and position is embedded into each of the models, and the salt bodies have a constant velocity of 4500 m/s. 
 All the models have the same size of $x\times z = 150 \times 80$ grid points with spatial interval $h=10$ m. 
We use eight-order in space and second-order in time finite differencing scheme to solve the acoustic wave equation with a 15 Hz Ricker wavelet.
Convolutional perfectly matched layer (CPML) absorbing boundary conditions \citep{komatitsch07} are applied on all four grid edges to reduce unwanted edge reflections.

For each model, 10 sources are evenly placed from (x, z) = (0.2, 0.0) km to (1.3, 0.0) km and shot gathers are simulated one after another. 
150 receivers are evenly placed from (0.0, 0.7) km to (1.5, 0.7) km, which are at the bottom of the models, and form a top-bottom geometry. Signals recorded by this geometry are mostly transmitted waves. Six sample models (a) with a representative acquisition geometry and their corresponding seismograms (b) for training are plotted in Figure~\ref{fig:model_sample1.eps}. 
%The true velocity models for generating the seismograms are used as ground truth for the training. 
%The labels used for training, however, contain only 0s for the salt area, and 1s for other area (see the output in Figure~\ref{fig:sketch_vnet.eps}). 
\fullplot{model_sample1.eps}{width=1.0\textwidth}
{(a) Six representative models for training, and their corresponding geometry seismograms (10 shots are generated for each model and only the fifth one is shown). The red dots indicate the source positions, and blue squares are receivers.}

The network is trained on a workstation with one GFORCE GTX 1080Ti GPU and 64 GB RAM. The generated seismic traces and their corresponding true velocity models are used to train the network with the stochastic gradient descent implementation of Pytorch (\url{www.pytorch.org}). The computational time for training is proportional to the size of the seismic traces and number of training samples, and it is also related with the complexity of the designed network. The training process in this paper took several hours to complete, and it only took a few seconds to apply the network to predict velocity models from seismic traces in the following testing process. Figure~\ref{fig:vnet_TB_cost.eps} shows the loss function, or the L2 norm between the predicted velocity model and ground truth decreases during the learning process. 

\plot{vnet_TB_cost.eps}{width=0.5\textwidth}
{The loss function decreases as the training proceeds.}

We are interested in the evolution of the network during the learning process. 10 network snapshots are captured before the training was terminated at 200 epoches. We apply those partially trained networks to one of the test samples (the first velocity model in Figure~\ref{fig:test_velocity_sample10.eps}a). The predicted velocity models using the 10 partially trained networks are shown in Figure~\ref{fig:network_evolution.eps} with their corresponding epoch status labelled at the bottom of each prediction. It shows that the network learns to fit the low wavenumber components of velocity models at early stages of the training process, and gradually fits the high wavenumber details in the velocity models as the training proceeds. This process is similar to a multi-scale FWI approach, but the mechanism is totally different as no initial model nor wave equations need to be provided to the neural network.

\plot{network_evolution.eps}{width=0.5\textwidth}
{The network evolution.}

The trained network is then tested with the 20 test samples. Six representative velocity models for testing are shown in Figure~\ref{fig:test_velocity_sample10.eps}(a), and 10 shot gathers are generated for each model with the same acquisition geometries as in the training set. The shot gathers are input to the trained network, and the output predictions are shown in Figure~\ref{fig:test_velocity_sample10.eps}(b). The results show that the network produces good approximations of the velocity models given the seismic traces.

\fullplot{test_velocity_sample10.eps}{width=1.0\textwidth}
{(a) Six representative velocity models for testing, and the corresponding predictions using the trained network.}

To quantitatively analyze the accuracy of predictions, we choose three horizontal positions x = 200 m, 700 m and 1300 m, respectively, and plot the predicted velocity values (red) against the true velocity values (blue) in velocity vs. depth profiles (Figure~\ref{fig:velocity_comb.eps}). The predicted values matches matches well with the ground truth.

\plot{velocity_comb.eps}{width=0.5\textwidth}
{The predicted and ground truth velocities plotted in velocity vs. depth profiles at three horizontal positions of the first test sample in Figure~\ref{fig:velocity_comb.eps}a}.


%\section{Discussion}


\section{Conclusions}
In this paper, we propose a data-driven technique that employs a modified fully convolutional network to build velocity models directly from recorded seismic traces. 
Multiple shots are learned as input channels to provide redundant information for predicting the velocity model, and this scheme helps to reduce this risk of overfitting. 
Once the network training is complete, it is extremely fast to build velocity models with the trained network and input seismic traces, and no human interventions are involved. 
Because the loss function is measured in the model domain, and no seismograms are generated when using the network to predict velocity models, so there is no problem of cycle skipping. 
Network snapshots during the training shows that the low wavenumber component of the velocity models are learnt first. The test results reach high accuracy using synthetic data. Applications to real seismic data may require a large database composed of real seismic traces and corresponding formerly interpreted velocity models for training the network.


\section{Acknowledgments}

The research leading to this paper is supported by the Young Talent Program (AUGA5710053217) from the Harbin Institute of Technology. 

\newpage

\bibliographystyle{seg}  % style file is seg.bst
\bibliography{att}

\end{document}
